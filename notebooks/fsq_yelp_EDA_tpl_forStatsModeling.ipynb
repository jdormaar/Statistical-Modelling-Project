{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W3P2 - PART3 - yelp_foursquareEDA\n",
    "\n",
    "assignment file part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from file\n",
    "df = pd.read_csv('../data/df_ctybks_toronto.csv')\n",
    "df.shape\n",
    "\n",
    "df_yelp = pd.read_csv('../data/yelpPOI/df_yelp_sun1436h.csv')\n",
    "# Save working copies:\n",
    "dfy = df_yelp.copy()\n",
    "\n",
    "df_fsq = pd.read_csv('../data/fsqPOI/df_fsq_sun1400h.csv')\n",
    "# Save working copies:\n",
    "dff = df_fsq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32709, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fsq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat-long</th>\n",
       "      <th>fsq_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>categories</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "      <th>popularity</th>\n",
       "      <th>open_now</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>my_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.665269,-79.319796</td>\n",
       "      <td>4deb8ba688774880e3387c0c</td>\n",
       "      <td>17065.0</td>\n",
       "      <td>Farmers' Market</td>\n",
       "      <td>[{'id': 17065, 'name': \"Farmers' Market\", 'ico...</td>\n",
       "      <td>Leslieville Farmers Market</td>\n",
       "      <td>40</td>\n",
       "      <td>43.664679</td>\n",
       "      <td>-79.319687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.86858</td>\n",
       "      <td>False</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-04 12:07:13.609094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lat-long                    fsq_id   cat_id    category_name  \\\n",
       "0  43.665269,-79.319796  4deb8ba688774880e3387c0c  17065.0  Farmers' Market   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [{'id': 17065, 'name': \"Farmers' Market\", 'ico...   \n",
       "\n",
       "                         name  distance   latitude  longitude  address  \\\n",
       "0  Leslieville Farmers Market        40  43.664679 -79.319687      NaN   \n",
       "\n",
       "   popularity  open_now  rating  rating_count                my_timestamp  \n",
       "0     0.86858     False     8.6           NaN  2022-12-04 12:07:13.609094  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fsq.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Normalizing the nested table values:\n",
    "\n",
    "The function which created the DataFrame made sure that each POI had at least one category name and ID, but we can see above that many have two or even three which can be normalized to flatten the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Normalize the categories:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_fsqcat \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mjson_normalize(df_fsq[\u001b[39m'\u001b[39;49m\u001b[39mcategories\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m df_fsqcat\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/base_env/lib/python3.10/site-packages/pandas/io/json/_normalize.py:446\u001b[0m, in \u001b[0;36m_json_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[1;32m    444\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data)\n\u001b[1;32m    445\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39m# check to see if a simple recursive function is possible to\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m# improve performance (see #15621) but only for cases such\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m# as pd.Dataframe(data) or pd.Dataframe(data, sep)\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    452\u001b[0m     record_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m meta \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39mand\u001b[39;00m max_level \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    457\u001b[0m ):\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Normalize the categories:\n",
    "df_fsqcat = pd.json_normalize(df_fsq['categories'][0])\n",
    "df_fsqcat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the resulting 3 columns into 3 tables in the example below:\n",
    "df_fsqcat0 = pd.json_normalize(df_fsqcat[0])\n",
    "df_fsqcat1 = pd.json_normalize(df_fsqcat[1])\n",
    "df_fsqcat2 = pd.json_normalize(df_fsqcat[2])\n",
    "df_fsqcat0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new category labels back onto the df: \n",
    "df_fsq['cat1_id'] = (df_fsqcat0['id'].astype('Int64'))\n",
    "df_fsq['cat1_name'] = df_fsqcat0['name']\n",
    "df_fsq['cat1_icon'] = df_fsqcat0['icon.prefix']\n",
    "df_fsq['cat1_icon.suffix'] = df_fsqcat0['icon.suffix']\n",
    "\n",
    "df_fsq['cat2_id'] = df_fsqcat1['id'].astype('Int64')\n",
    "df_fsq['cat2_name'] = df_fsqcat1['name']\n",
    "df_fsq['cat2_icon'] = df_fsqcat1['icon.prefix']\n",
    "df_fsq['cat2_icon.suffix'] = df_fsqcat1['icon.suffix']\n",
    "\n",
    "df_fsq['cat3_id'] = df_fsqcat2['id'].astype('Int64')\n",
    "df_fsq['cat3_name'] = df_fsqcat2['name']\n",
    "df_fsq['cat3_icon'] = df_fsqcat2['icon.prefix']\n",
    "df_fsq['cat3_icon.suffix'] = df_fsqcat2['icon.suffix']\n",
    "\n",
    "# Remove the now redundant 'category' and 'name' columns:\n",
    "df_fsq = df_fsq.drop(['categories', 'category_name', 'cat_id', ], axis = 1)\n",
    "\n",
    "df_fsq.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOURSQUARE POI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone a working copy:\n",
    "dff = df_fsq.copy()\n",
    "\n",
    "# Drop columns from our copy df not currently needed:\n",
    "dff = dff.drop(['fsq_id', 'cat1_icon', 'cat2_icon', 'cat3_icon', 'cat1_icon.suffix', 'cat2_icon.suffix', 'cat3_icon.suffix', 'address'], axis = 1)\n",
    "dff.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the timestamp data to the Toronto's time zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create both timezone objects\n",
    "old_timezone = pytz.timezone(\"US/Mountain\")\n",
    "new_timezone = pytz.timezone(\"US/Eastern\")\n",
    "\n",
    "# Confirm current timezone\n",
    "print(dff['my_timestamp'].iloc[0])\n",
    "\n",
    "# two-step process\n",
    "for i in range(dff.shape[0]):\n",
    "  localized_timestamp = old_timezone.localize(dff['my_timestamp'].iloc[i])\n",
    "  dff['my_timestamp'].iloc[i] = localized_timestamp.astimezone(new_timezone)\n",
    "  dff['my_timestamp'].iloc[i] = localized_timestamp.astimezone(new_timezone)\n",
    "\n",
    "\n",
    "# Has converted to new timezone:\n",
    "print(dff['my_timestamp'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv(f'../data/df_fsq_1400h.csv', index= False)\n",
    "\n",
    "dff.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get rid of the time stamp and save in table name instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDataRunTime = \n",
    "\n",
    "#get rid of the time stamp and save in table name instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE IT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the saving path and name for stats model df\n",
    "\n",
    "df_fsq.to_csv(f'../data/df_fsq{dfDataRunTime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Normalizing the nested table values:\n",
    "\n",
    "The function which created the DataFrame made sure that each POI had at least one category name and alias, but we can see above that many have two or even three which can be normalized to flatten the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the categories:\n",
    "df_yelpcat = pd.json_normalize(df_yelp['categories'][0])\n",
    "df_yelpcat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the resulting 3 columns into 3 tables in the example below:\n",
    "df_yelpcat0 = pd.json_normalize(df_yelpcat[0])\n",
    "df_yelpcat1 = pd.json_normalize(df_yelpcat[1])\n",
    "df_yelpcat2 = pd.json_normalize(df_yelpcat[2])\n",
    "df_yelpcat0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new category labels back onto the df: \n",
    "df_yelp['cat1_alias'] = df_yelpcat0['alias']\n",
    "df_yelp['cat1_title'] = df_yelpcat0['title']\n",
    "\n",
    "df_yelp['cat2_alias'] = df_yelpcat1['alias']\n",
    "df_yelp['cat2_title'] = df_yelpcat1['title']\n",
    "\n",
    "df_yelp['cat3_alias'] = df_yelpcat2['alias']\n",
    "df_yelp['cat3_title'] = df_yelpcat2['title']\n",
    "\n",
    "# Remove the now redundant 'category' and 'name' columns:\n",
    "df_yelp = df_yelp.drop(['categories', 'category_name'], axis = 1)\n",
    "\n",
    "df_yelp.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE IT!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp.to_csv(f'../data/yelpPOI/df_yelp{datetime.now()}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)\n",
    "\n",
    "### YELP POI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone a working copy:\n",
    "df = df_yelp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the addresses look chunky which diminishes the aesthetic of the table, and I expect this format might be useful for printing them in mailing format.  I won't be using it for my analysis at this point anyway, but I would certainly research this more before I made decisions about changing the format.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns from our copy df not currently needed:\n",
    "df = df.drop(['address', 'cat1_alias', 'cat2_alias', 'cat3_alias'], axis = 1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flip the \"is_closed\" column to remove the confusing double negative, and enable foursquare comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_closed'] = df['is_closed'] == False\n",
    "# Rename the heading to match:\n",
    "df = df.rename(columns = {'is_closed':'is_open'})\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the timestamp data to the Toronto's time zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create both timezone objects\n",
    "old_timezone = pytz.timezone(\"US/Mountain\")\n",
    "new_timezone = pytz.timezone(\"US/Eastern\")\n",
    "\n",
    "# Confirm current timezone\n",
    "print(df['my_timestamp'].iloc[0])\n",
    "\n",
    "# two-step process\n",
    "for i in range(df.shape[0]):\n",
    "  localized_timestamp = old_timezone.localize(df['my_timestamp'].iloc[i])\n",
    "  df['my_timestamp'].iloc[i] = localized_timestamp.astimezone(new_timezone)\n",
    "  df['my_timestamp'].iloc[i] = localized_timestamp.astimezone(new_timezone)\n",
    "\n",
    "\n",
    "# Has converted to new timezone:\n",
    "print(df['my_timestamp'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance'] = round(df['distance'], 1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df['my_timestamp'].iloc[0]\n",
    "print(test)\n",
    "print(datetime.date(test))\n",
    "print(datetime.time(test))\n",
    "print(len('2022-12-04 00:09'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical encoding: price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['price'].value_counts())\n",
    "print(df['price'].isna().value_counts())\n",
    "df['price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order in array above will be same as the keys,\n",
    "keys = df['price'].unique()\n",
    "# Setting ordinal numerical values to match the order:\n",
    "values = [2, 1, 3, None, 4]\n",
    "price_map = dict(zip(keys, values))\n",
    "price_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace\n",
    "df['price'] = df['price'].map(price_map)\n",
    "# Validate counts unaffected:\n",
    "print(df['price'].value_counts())\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE IT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'../data/df_yelp_1440h.csv', index= False)\n",
    "\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('base_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "39512f3c2a1741d7f752d45a133d4514127029333ea14bc2f3c6c5e6759b9029"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
